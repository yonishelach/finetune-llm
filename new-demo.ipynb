{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906e38b6-168a-47cb-9320-2acdd16b0b37",
   "metadata": {},
   "source": [
    "# 1. Showing the pretrained model knows nothing about MLRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "288837b2-6984-483d-8d17-8cbc01fe75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c763708-f0e5-4a53-b788-64e4c2634973",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-medium\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49dd97e6-b8f8-4ac7-980c-8aa18f10bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is MLRun?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1e98ec1-859e-4306-ac0e-be3b714ef5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is MLRun? MLRun is a complete web-based application built for interactive analysis and training of machine learning systems. MLRun allows trained training tasks to be used as a learning source in the context of data visualization or data scientific development. MLRun also enables you to generate model files with visualisations, and provides access to training files using a graphical user interface. Furthermore, MLRun is used by numerous data science and AI research labs.\n",
      "\n",
      "Requirements You'll need:\n",
      "\n",
      "A computer running Visual Studio 2014-2017 (2013, 2017, 2016), and Python 3 to install Python 3 in a Windows machine.\n",
      "\n",
      "A web browser to view the document, use the mouse or keyboard to browse the visualisation sources. To find a\n"
     ]
    }
   ],
   "source": [
    "print(generator(prompt, max_length=150, pad_token_id=tokenizer.eos_token_id)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26437209-fa75-496f-8d12-19751ba88530",
   "metadata": {},
   "source": [
    "# Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e3c3db-a8ea-4751-891e-3217dc00c6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-05-17 08:57:17,332 [info] loaded project mlopspedia-newer from MLRun DB\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "from src.project_setup import create_and_set_project\n",
    "\n",
    "project = create_and_set_project(\n",
    "    git_source=\"git://github.com/yonishelach/learn-docs.git#main\",\n",
    "    name=\"mlopspedia-newer\",\n",
    "    default_image=\"yonishelach/mlrun-hf\",\n",
    "    user_project=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66deeb6-7472-4642-8a11-996422cd3091",
   "metadata": {},
   "source": [
    "___\n",
    "<a id=\"full-workflow\"></a>\n",
    "## Run full LLM life-cycle workflow\n",
    "\n",
    "Run the training pipeline (in [training_workflow.py](./src/training_workflow.py)) by using `project.run(workflow name, ...)`:\n",
    "                                                          \n",
    "* `collect_html_to_text_files` (Data Collection) - Collect all text from given html urls into `.txt` files.\n",
    "* `prepare_dataset` (Preprocess Data) - Join the `.txt` files, reformatting the text into our \"Subject - Content\" prompt template. We made every header (`<h>` tags) a *subject* of a prompt, and the text (`<p>` tags) under it as its *content*.\n",
    "* `train` - Fine-tune the LLM on the data. We'll run the training on **OpenMPI** and we will use **DeepSpeed** for distributing the model and data between multiple workers, splitting the work between nodes and GPUs.\n",
    "* `evaluate` - Evaluate our model using the *Perplexity* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ea5ec6-cb78-44db-aac7-97e52ce591db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>Pipeline running (id=e2b71dcf-4287-4bd2-96b2-db1604ca60c7), <a href=\"https://dashboard.default-tenant.app.llm.iguazio-cd1.com/mlprojects/mlopspedia-newer-yonis/jobs/monitor-workflows/workflow/e2b71dcf-4287-4bd2-96b2-db1604ca60c7\" target=\"_blank\"><b>click here</b></a> to view the details in MLRun UI</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: kfp Pages: 1 -->\n",
       "<svg width=\"186pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 186.08 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>kfp</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-256 182.08,-256 182.08,4 -4,4\"/>\n",
       "<!-- mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1072228045 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1072228045</title>\n",
       "<ellipse fill=\"green\" stroke=\"black\" cx=\"59.04\" cy=\"-90\" rx=\"33.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"59.04\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">train</text>\n",
       "</g>\n",
       "<!-- mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1263243558 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1263243558</title>\n",
       "<ellipse fill=\"green\" stroke=\"black\" cx=\"89.04\" cy=\"-18\" rx=\"50.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"89.04\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">evaluate</text>\n",
       "</g>\n",
       "<!-- mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1072228045&#45;&gt;mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1263243558 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1072228045&#45;&gt;mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1263243558</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.15,-72.41C69.61,-64.34 73.86,-54.43 77.75,-45.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"81.05,-46.53 81.78,-35.96 74.62,-43.77 81.05,-46.53\"/>\n",
       "</g>\n",
       "<!-- mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1081145960 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1081145960</title>\n",
       "<ellipse fill=\"green\" stroke=\"black\" cx=\"89.04\" cy=\"-234\" rx=\"78.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"89.04\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">data&#45;collection</text>\n",
       "</g>\n",
       "<!-- mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;4230849693 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;4230849693</title>\n",
       "<ellipse fill=\"green\" stroke=\"black\" cx=\"89.04\" cy=\"-162\" rx=\"89.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"89.04\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">data&#45;preparation</text>\n",
       "</g>\n",
       "<!-- mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1081145960&#45;&gt;mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;4230849693 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1081145960&#45;&gt;mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;4230849693</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M89.04,-215.7C89.04,-207.98 89.04,-198.71 89.04,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.54,-190.1 89.04,-180.1 85.54,-190.1 92.54,-190.1\"/>\n",
       "</g>\n",
       "<!-- mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;4230849693&#45;&gt;mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1072228045 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;4230849693&#45;&gt;mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1072228045</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M81.78,-144.05C78.32,-135.97 74.09,-126.12 70.23,-117.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"73.39,-115.6 66.24,-107.79 66.96,-118.36 73.39,-115.6\"/>\n",
       "</g>\n",
       "<!-- mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;4230849693&#45;&gt;mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1263243558 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;4230849693&#45;&gt;mlops&#45;bot&#45;master&#45;pipeline&#45;hnvks&#45;1263243558</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M93.91,-143.98C96.61,-133.67 99.68,-120.19 101.04,-108 102.82,-92.1 102.82,-87.9 101.04,-72 100.08,-63.43 98.28,-54.22 96.36,-45.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"99.71,-44.89 93.91,-36.02 92.91,-46.57 99.71,-44.89\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fecad95efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Run Results</h2><h3>[info] Workflow e2b71dcf-4287-4bd2-96b2-db1604ca60c7 finished, state=Succeeded</h3><br>click the hyper links below to see detailed results<br><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"6a1f7bfd2e0a4aa7b0f91ecdf81ac8c5\"><a href=\"https://dashboard.default-tenant.app.llm.iguazio-cd1.com/mlprojects/mlopspedia-newer-yonis/jobs/monitor/6a1f7bfd2e0a4aa7b0f91ecdf81ac8c5/overview\" target=\"_blank\" >...f81ac8c5</a></div></td>\n",
       "      <td>May 17 07:06:33</td>\n",
       "      <td>completed</td>\n",
       "      <td>evaluate</td>\n",
       "      <td><div class=\"dictlist\">model_path=store://artifacts/mlopspedia-newer-yonis/gpt2-medium-mlrun:e2b71dcf-4287-4bd2-96b2-db1604ca60c7</div></td>\n",
       "      <td><div class=\"dictlist\">perplexity=5.092374324798584</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><div title=\"2e692e0938a24ecb8870f625cd7cf47b\"><a href=\"https://dashboard.default-tenant.app.llm.iguazio-cd1.com/mlprojects/mlopspedia-newer-yonis/jobs/monitor/2e692e0938a24ecb8870f625cd7cf47b/overview\" target=\"_blank\" >...cd7cf47b</a></div></td>\n",
       "      <td>May 17 06:52:56</td>\n",
       "      <td>completed</td>\n",
       "      <td>train</td>\n",
       "      <td><div class=\"dictlist\">model_name=gpt2-medium-mlrun</div><div class=\"dictlist\">pretrained_tokenizer=gpt2-medium</div><div class=\"dictlist\">pretrained_model=gpt2-medium</div><div class=\"dictlist\">model_class=transformers.GPT2LMHeadModel</div><div class=\"dictlist\">tokenizer_class=transformers.GPT2Tokenizer</div><div class=\"dictlist\">TRAIN_num_train_epochs=15</div><div class=\"dictlist\">TRAIN_fp16=True</div><div class=\"dictlist\">TRAIN_bf16=False</div><div class=\"dictlist\">TRAIN_per_device_train_batch_size=4</div><div class=\"dictlist\">TRAIN_logging_strategy=epoch</div><div class=\"dictlist\">use_deepspeed=True</div></td>\n",
       "      <td><div class=\"dictlist\">loss=1.6697</div><div class=\"dictlist\">learning_rate=5e-05</div><div class=\"dictlist\">train_runtime=463.2184</div><div class=\"dictlist\">train_samples_per_second=18.62</div><div class=\"dictlist\">train_steps_per_second=0.291</div><div class=\"dictlist\">total_flos=8471017684992.0</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><div title=\"1a41c14f88084c80b021e19e38dffac8\"><a href=\"https://dashboard.default-tenant.app.llm.iguazio-cd1.com/mlprojects/mlopspedia-newer-yonis/jobs/monitor/1a41c14f88084c80b021e19e38dffac8/overview\" target=\"_blank\" >...38dffac8</a></div></td>\n",
       "      <td>May 17 06:34:09</td>\n",
       "      <td>completed</td>\n",
       "      <td>data-preparation</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><div title=\"cdeaeadf5be3413c85105823ae36ed13\"><a href=\"https://dashboard.default-tenant.app.llm.iguazio-cd1.com/mlprojects/mlopspedia-newer-yonis/jobs/monitor/cdeaeadf5be3413c85105823ae36ed13/overview\" target=\"_blank\" >...ae36ed13</a></div></td>\n",
       "      <td>May 17 06:33:29</td>\n",
       "      <td>completed</td>\n",
       "      <td>data-collection</td>\n",
       "      <td><div class=\"dictlist\">urls=https://www.iguazio.com/blog/</div></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "workflow_run = project.run(\n",
    "    name=\"training_workflow\",\n",
    "    arguments={\n",
    "        \"html_links\": 'https://www.iguazio.com/blog/',\n",
    "        \"model_name\": \"gpt2-medium-mlrun\",\n",
    "        \"pretrained_tokenizer\": \"gpt2-medium\",\n",
    "        \"pretrained_model\": \"gpt2-medium\",\n",
    "        \"model_class\": \"transformers.GPT2LMHeadModel\",\n",
    "        \"tokenizer_class\": \"transformers.GPT2Tokenizer\",\n",
    "        \"epochs\": 15,\n",
    "        \"use_deepspeed\": True,\n",
    "    },\n",
    "    watch=True,\n",
    "    dirty=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c4ca092-cce3-4cf0-af00-bc69cae01f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_url = project.get_artifact_uri(\"gpt2-medium-mlrun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a1b540-c40e-4308-8e30-b43eaf8c0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = 'store://artifacts/mlopspedia-newer-yonis/gpt2-medium-mlrun'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11910dbc-8c31-4efd-b092-cdb1a649c4f2",
   "metadata": {},
   "source": [
    "# 3. Deploying and serving pipeline with GRadio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "442e2d73-45fd-4264-92d1-9cfea8620066",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_function = project.get_function(\"serving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08594367-5e87-4bf3-8598-d72a6759355b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"785pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 785.45 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-40 781.45,-40 781.45,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"38.55,-0.05 40.7,-0.15 42.83,-0.3 44.92,-0.49 46.98,-0.74 48.99,-1.03 50.95,-1.36 52.84,-1.75 54.66,-2.18 56.4,-2.65 58.06,-3.16 59.63,-3.71 61.11,-4.31 62.49,-4.94 63.76,-5.61 64.93,-6.31 65.99,-7.04 66.93,-7.8 67.77,-8.59 68.48,-9.41 69.09,-10.25 69.58,-11.11 69.95,-11.99 70.21,-12.89 70.36,-13.8 70.4,-14.72 70.33,-15.65 70.16,-16.59 69.89,-17.53 69.53,-18.47 69.07,-19.41 68.52,-20.35 67.89,-21.28 67.18,-22.2 66.4,-23.11 65.55,-24.01 64.63,-24.89 63.65,-25.75 62.62,-26.59 61.53,-27.41 60.4,-28.2 59.23,-28.96 58.02,-29.69 56.78,-30.39 55.5,-31.06 54.2,-31.69 52.88,-32.29 51.53,-32.84 50.17,-33.35 48.79,-33.82 47.4,-34.25 46,-34.64 44.59,-34.97 43.17,-35.26 41.75,-35.51 40.32,-35.7 38.89,-35.85 37.45,-35.95 36.02,-36 34.58,-36 33.15,-35.95 31.71,-35.85 30.28,-35.7 28.85,-35.51 27.43,-35.26 26.01,-34.97 24.6,-34.64 23.2,-34.25 21.81,-33.82 20.43,-33.35 19.07,-32.84 17.72,-32.29 16.4,-31.69 15.1,-31.06 13.82,-30.39 12.58,-29.69 11.37,-28.96 10.2,-28.2 9.07,-27.41 7.98,-26.59 6.95,-25.75 5.97,-24.89 5.05,-24.01 4.2,-23.11 3.42,-22.2 2.71,-21.28 2.08,-20.35 1.53,-19.41 1.07,-18.47 0.71,-17.53 0.44,-16.59 0.27,-15.65 0.2,-14.72 0.24,-13.8 0.39,-12.89 0.65,-11.99 1.02,-11.11 1.51,-10.25 2.11,-9.41 2.83,-8.59 3.66,-7.8 4.61,-7.04 5.67,-6.31 6.84,-5.61 8.11,-4.94 9.49,-4.31 10.97,-3.71 12.54,-3.16 14.2,-2.65 15.94,-2.18 17.76,-1.75 19.65,-1.36 21.61,-1.03 23.62,-0.74 25.68,-0.49 27.77,-0.3 29.9,-0.15 32.05,-0.05 34.22,0 36.38,0 38.55,-0.05\"/>\n",
       "<text text-anchor=\"middle\" x=\"35.3\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">start</text>\n",
       "</g>\n",
       "<!-- preprocess -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>preprocess</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"168.34\" cy=\"-18\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.34\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">preprocess</text>\n",
       "</g>\n",
       "<!-- _start&#45;&gt;preprocess -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;preprocess</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M70.05,-18C78.23,-18 87.29,-18 96.49,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"96.5,-21.5 106.5,-18 96.5,-14.5 96.5,-21.5\"/>\n",
       "</g>\n",
       "<!-- mlopspedia -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>mlopspedia</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"329.78\" cy=\"-18\" rx=\"63.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"329.78\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">mlopspedia</text>\n",
       "</g>\n",
       "<!-- preprocess&#45;&gt;mlopspedia -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>preprocess&#45;&gt;mlopspedia</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.53,-18C238.77,-18 247.29,-18 255.71,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"255.91,-21.5 265.91,-18 255.91,-14.5 255.91,-21.5\"/>\n",
       "</g>\n",
       "<!-- postprocess -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>postprocess</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"495.77\" cy=\"-18\" rx=\"66.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"495.77\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">postprocess</text>\n",
       "</g>\n",
       "<!-- mlopspedia&#45;&gt;postprocess -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>mlopspedia&#45;&gt;postprocess</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M393.72,-18C402,-18 410.56,-18 419.03,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"419.29,-21.5 429.29,-18 419.29,-14.5 419.29,-21.5\"/>\n",
       "</g>\n",
       "<!-- toxicity&#45;classifier -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>toxicity&#45;classifier</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"687.76\" cy=\"-18\" rx=\"89.88\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"687.76\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">toxicity&#45;classifier</text>\n",
       "</g>\n",
       "<!-- postprocess&#45;&gt;toxicity&#45;classifier -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>postprocess&#45;&gt;toxicity&#45;classifier</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M562.15,-18C570.41,-18 578.99,-18 587.63,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"587.76,-21.5 597.76,-18 587.76,-14.5 587.76,-21.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f14edb9c4c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the topology and get the graph object:\n",
    "graph = serving_function.set_topology(\"flow\", engine=\"async\")\n",
    "\n",
    "graph.to(handler=\"preprocess\", name=\"preprocess\") \\\n",
    "    .to(\"LLMModelServer\",\n",
    "        name=\"mlopspedia\",\n",
    "        model_path=project.get_artifact_uri(\"gpt2-medium-mlrun\"),\n",
    "        model_class=\"GPT2LMHeadModel\",\n",
    "        tokenizer_name=\"gpt2\",\n",
    "        tokenizer_class=\"GPT2Tokenizer\",\n",
    "        use_deepspeed=False) \\\n",
    "    .to(handler=\"postprocess\", name=\"postprocess\") \\\n",
    "    .to(\"ToxicityClassifierModelServer\",\n",
    "        name=\"toxicity-classifier\",\n",
    "        threshold=0.7).respond()\n",
    "\n",
    "# Plot to graph:\n",
    "serving_function.plot(rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2efaff89-86de-4fa1-9bcb-cb97b0a34b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f14901e7cd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_function.with_limits(gpus=1)\n",
    "serving_function.spec.readiness_timeout = 3000\n",
    "project.set_function(serving_function, with_repo=True)\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5819e-aea0-48d2-9027-e85ce3b41aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-05-17 07:15:30,865 [info] Starting remote function deploy\n",
      "2023-05-17 07:15:31  (info) Deploying function\n",
      "2023-05-17 07:15:31  (info) Building\n",
      "2023-05-17 07:15:31  (info) Staging files and preparing base images\n",
      "2023-05-17 07:15:31  (info) Building processor image\n",
      "2023-05-17 07:31:32  (info) Build complete\n"
     ]
    }
   ],
   "source": [
    "# Deploy the serving function:\n",
    "deployment = mlrun.deploy_function(\"serving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4055d2ab-cebc-4456-acb6-80627040416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot load darkdefault. Caught Exception: The space darkdefault does not exist\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "\n",
    "\n",
    "serving_url = deployment.outputs[\"endpoint\"]\n",
    "\n",
    "def generate(text, temprature, max_length, top_p, top_k, repetition_penalty):\n",
    "    inputs = {\n",
    "        \"text\": text,\n",
    "        \"temprature\": temprature,\n",
    "        \"max_length\": max_length,\n",
    "        \"top_p\": top_p,\n",
    "        \"top_k\": top_k,\n",
    "        \"repetition_penalty\": repetition_penalty,\n",
    "    }\n",
    "    # call the serving function with the input text\n",
    "    resp = requests.post(serving_url, data=inputs)\n",
    "    return resp.json()[\"outputs\"]\n",
    "    \n",
    "    \n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "         \"\"\"\n",
    "         # MLOps Chat 🚀\n",
    "         Ask a question about MLOps and set the inference parametes below.\n",
    "         \"\"\"\n",
    "    )\n",
    "    text = gr.Textbox(label=\"MLOps Subject to ask about:\", placeholder=\"Please insert text\", value=\"What is machine learning?\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            temprature = gr.Slider(0, 1, value=0.9, label=\"Temperature\", info=\"Choose betwen 0 and 1\")\n",
    "            max_length = gr.Slider(0, 1500, value=150, label=\"Maximum length\", info=\"Choose betwen 0 and 1500\")\n",
    "            top_p = gr.Slider(0, 1, value=0.9, label=\"Top P\", info=\"Choose betwen 0 and 1\")\n",
    "            top_k = gr.Slider(0, 500, value=50, label=\"Top k\", info=\"Choose betwen 0 and 500\")\n",
    "            repetition_penalty = gr.Slider(0, 1, value=1, label=\"repetition penalty\", info=\"Choose betwen 0 and 1\")\n",
    "        with gr.Column(scale=4):\n",
    "            output = [gr.Textbox(label=\"Generated Answer\")]\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    btn.click(fn=generate, inputs=[text, temprature, max_length, top_p, top_k, repetition_penalty], outputs=output)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ef771d3-ecb1-4cde-a9bc-6ebf8b76d37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "Running on public URL: https://9bcbe711d890a3ed7c.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9bcbe711d890a3ed7c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb0c3a-fab5-49e2-9138-b6eaf912a951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-base",
   "language": "python",
   "name": "conda-env-mlrun-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
