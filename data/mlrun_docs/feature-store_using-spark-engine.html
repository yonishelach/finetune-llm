
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Ingest features with Spark</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    <link rel="stylesheet" type="text/css" href="/_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="/_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.mlrun.org/en/stable/feature-store/using-spark-engine.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Develop and train models" href="../development/index.html" />
    <link rel="prev" title="Ingest data using the feature store" href="../data-prep/ingest-data-fs.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-MV26G85');</script>
<!-- End Google Tag Manager -->


  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="/_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": false, "api_host": "https://readthedocs.org", "build_date": "2022-12-01T09:20:30Z", "builder": "sphinx", "canonical_url": null, "commit": "9933138d", "docroot": "/docs/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "feature-store/using-spark-engine", "programming_language": "py", "project": "mlrun", "proxied_api_host": "/_", "source_suffix": ".md", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "UA-101852366-5", "version": "stable"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="/_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/MLRun_Character.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MLRun basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../index.html">
   Using MLRun
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../architecture.html">
     MLRun architecture
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops-dev-flow.html">
   MLOps development workflow
   <!-- omit in toc -->
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../tutorial/index.html">
   Tutorials and Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorial/01-mlrun-basics.html">
     Quick start tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorial/02-model-training.html">
     Train, compare, and register models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorial/03-model-serving.html">
     Serving pre-trained ML/DL models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorial/04-pipeline.html">
     Projects and automated ML pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorial/05-model-monitoring.html">
     Model monitoring and drift detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorial/06-add-mlops-to-code.html">
     Add MLOps to existing code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorial/07-batch-infer.html">
     Batch inference and drift detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basic-demo.html">
     Feature store example (stocks)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://github.com/mlrun/demos">
     MLRun demos repository
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../install.html">
   Installation and setup guide
   <!-- omit in toc -->
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../install/local-docker.html">
     Install MLRun locally using Docker
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../install/kubernetes.html">
     Install MLRun on Kubernetes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../install/aws-install.html">
     Install MLRun on AWS
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../install/remote.html">
     Set up your client environment
     <!-- omit in toc -->
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Core components
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../projects/project.html">
   Projects and automation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../projects/create-project.html">
     Create, save, and use projects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../projects/load-project.html">
     Load and run projects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../projects/run-build-deploy.html">
     Run, build, and deploy functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../projects/build-run-workflows-pipelines.html">
     Build and run workflows/pipelines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../projects/ci-integration.html">
     CI/CD integration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../secrets.html">
     Working with secrets
     <!-- omit in toc -->
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../runtimes/functions.html">
   Serverless functions
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../runtimes/functions-architecture.html">
     Functions architecture
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../concepts/functions-overview.html">
     Kinds of functions (runtimes)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../runtimes/dask-overview.html">
       Dask distributed runtime
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
      <label for="toctree-checkbox-7">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../runtimes/dask-mlrun.html">
         Running Dask on the cluster with mlrun
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../runtimes/dask-pipeline.html">
         Pipelines using Dask, Kubeflow and MLRun
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../runtimes/horovod.html">
       MPIJob and Horovod runtime
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../runtimes/spark-operator.html">
       Spark Operator runtime
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../concepts/nuclio-real-time-functions.html">
       Nuclio real-time functions
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../runtimes/create-and-use-functions.html">
     Create and use functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../runtimes/mlrun_code_annotations.html">
     Converting notebooks to function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../runtimes/function-storage.html">
     Attach storage to functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../runtimes/images.html">
     Images and their usage in MLRun
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../runtimes/image-build.html">
     Build function image
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/node-affinity.html">
     Node affinity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../runtimes/configuring-job-resources.html">
     Managing job resources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../runtimes/load-from-hub.html">
     Function Hub
     <!-- omit in toc -->
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../concepts/data.html">
   Data and artifacts
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../store/datastore.html">
     Data stores
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../store/data-items.html">
     Data items
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../store/artifacts.html">
     Artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../store/models.html">
     Model Artifacts
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="feature-store.html">
   Feature store
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="feature-store-overview.html">
     Feature store overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="feature-sets.html">
     Feature sets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="transformations.html">
     Feature set transformations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="feature-vectors.html">
     Creating and using feature vectors
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="end-to-end-demo/index.html">
     Feature store end-to-end demo
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="end-to-end-demo/01-ingest-datasources.html">
       Part 1: Data Ingestion
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="end-to-end-demo/02-create-training-model.html">
       Part 2: Training
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="end-to-end-demo/03-deploy-serving-model.html">
       Part 3: Serving
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="end-to-end-demo/04-pipeline.html">
       Part 4: Automated ML pipeline
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../concepts/runs-workflows.html">
   Batch runs and workflows
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/mlrun-execution-context.html">
     MLRun execution context
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/decorators-and-auto-logging.html">
     Decorators and auto-logging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/submitting-tasks-jobs-to-functions.html">
     Running a task (job)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/workflow-overview.html">
     Running a multi-stage workflow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../concepts/scheduled-jobs.html">
     Scheduled jobs and workflows
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../serving/serving-graph.html">
   Real-time serving pipelines (graphs)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../serving/getting-started.html">
     Getting started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../serving/use-cases.html">
     Use cases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../serving/realtime-pipelines.html">
     Graph concepts and state machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../serving/model-serving-get-started.html">
     Model serving graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../serving/writing-custom-steps.html">
     Writing custom steps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../serving/available-steps.html">
     Built-in steps
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../serving/demos.html">
     Demos and tutorials
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../serving/distributed-graph.html">
       Distributed (multi-function) pipeline example
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../serving/graph-example.html">
       Advanced model serving graph - notebook example
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../serving/graph-ha-cfg.html">
     Serving graph high availability configuration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../serving/pipelines-error-handling.html">
     Error handling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../concepts/monitoring.html">
   Model monitoring
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MLOps tasks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../data-prep/index.html">
   Ingest and process data
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../data-prep/ingesting_data.html">
     Using data sources and items
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-prep/logging_datasets.html">
     Logging datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../runtimes/spark-operator.html">
     Spark Operator runtime
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-prep/ingest-data-fs.html">
     Ingest data using the feature store
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Ingest features with Spark
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../development/index.html">
   Develop and train models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../development/model-training-tracking.html">
     Model training and tracking
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
    <label for="toctree-checkbox-16">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../training/create-a-basic-training-job.html">
       Create a basic training job
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../training/working-with-data-and-model-artifacts.html">
       Working with data and model artifacts
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../concepts/auto-logging-mlops.html">
       Automated experiment tracking
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../training/built-in-training-function.html">
       Using the built-in training function
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../hyper-params.html">
       Hyperparameter tuning optimization
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="retrieve-offline-data.html">
     Training with the feature store
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../deployment/index.html">
   Deploy models and applications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../serving/serving-overview.html">
     Real-time deployment
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
    <label for="toctree-checkbox-18">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../serving/built-in-model-serving.html">
       Using built-in model serving classes
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../serving/custom-model-serving-class.html">
       Build your own model serving class
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../serving/test-deploy-model-server.html">
       Test and deploy a model server
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../serving/model-api.html">
       Model serving API
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="training-serving.html">
     Serving with the feature store
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deployment/batch_inference.html">
     Batch inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../serving/canary.html">
     Canary and rolling upgrades
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../monitoring/index.html">
   Monitor and alert
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../monitoring/model-monitoring-deployment.html">
     Model monitoring overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../monitoring/initial-setup-configuration.html">
     Enable model monitoring
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../genindex.html">
   API index
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../api/index.html">
   API by module
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../api/mlrun.frameworks/index.html">
     mlrun.frameworks
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/mlrun.frameworks/mlrun.frameworks.auto_mlrun.html">
       AutoMLRun
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/mlrun.frameworks/mlrun.frameworks.tf_keras.html">
       TensorFlow.Keras
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/mlrun.frameworks/mlrun.frameworks.pytorch.html">
       PyTorch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/mlrun.frameworks/mlrun.frameworks.sklearn.html">
       SciKit-Learn
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/mlrun.frameworks/mlrun.frameworks.xgboost.html">
       XGBoost
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../api/mlrun.frameworks/mlrun.frameworks.lgbm.html">
       LightGBM
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.html">
     mlrun
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.artifacts.html">
     mlrun.artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.config.html">
     mlrun.config
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.datastore.html">
     mlrun.datastore
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.db.html">
     mlrun.db
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.execution.html">
     mlrun.execution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.feature_store.html">
     mlrun.feature_store
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.model.html">
     mlrun.model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.platforms.html">
     mlrun.platforms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.projects.html">
     mlrun.projects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.run.html">
     mlrun.run
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.runtimes.html">
     mlrun.runtimes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/mlrun.serving.html">
     mlrun.serving
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../api/storey.transformations.html">
     storey.transformations - Graph transformations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cli.html">
   Command-Line Interface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../glossary.html">
   Glossary
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            By <a href="https://www.iguazio.com/">Iguazio</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/mlrun/mlrun"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/mlrun/mlrun/issues/new?title=Issue%20on%20page%20%2Ffeature-store/using-spark-engine.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/mlrun/mlrun/edit/development/docs/feature-store/using-spark-engine.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/feature-store/using-spark-engine.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#local-spark-ingestion-example">
   Local Spark ingestion example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#remote-spark-ingestion-example">
   Remote Spark ingestion example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-operator-ingestion-example">
   Spark operator ingestion example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-dataframe-ingestion-example">
   Spark dataframe ingestion example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-over-s3-full-flow-example">
   Spark over S3 - full flow example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-ingestion-from-snowflake-example">
   Spark ingestion from Snowflake example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-ingestion-from-azure-example">
   Spark ingestion from Azure example
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Ingest features with Spark</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#local-spark-ingestion-example">
   Local Spark ingestion example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#remote-spark-ingestion-example">
   Remote Spark ingestion example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-operator-ingestion-example">
   Spark operator ingestion example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-dataframe-ingestion-example">
   Spark dataframe ingestion example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-over-s3-full-flow-example">
   Spark over S3 - full flow example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-ingestion-from-snowflake-example">
   Spark ingestion from Snowflake example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spark-ingestion-from-azure-example">
   Spark ingestion from Azure example
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="ingest-features-with-spark">
<h1>Ingest features with Spark<a class="headerlink" href="#ingest-features-with-spark" title="Permalink to this headline">#</a></h1>
<p>The feature store supports using Spark for ingesting, transforming, and writing results to data targets. When
using Spark, the internal execution graph is executed synchronously by utilizing a Spark session to perform read and
write operations, as well as potential transformations on the data. Executing synchronously means that the
source data is fully read into a data-frame that is processed, writing the output to the targets defined.</p>
<p>To use Spark as the transformation engine in ingestion, follow these steps:</p>
<p>When constructing the <a class="reference internal" href="../api/mlrun.feature_store.html#mlrun.feature_store.FeatureSet" title="mlrun.feature_store.FeatureSet"><code class="xref py py-class docutils literal notranslate"><span class="pre">FeatureSet</span></code></a> object, pass an <code class="docutils literal notranslate"><span class="pre">engine</span></code> parameter and set it
to <code class="docutils literal notranslate"><span class="pre">spark</span></code>. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">feature_set</span> <span class="o">=</span> <span class="n">fstore</span><span class="o">.</span><span class="n">FeatureSet</span><span class="p">(</span><span class="s2">&quot;stocks&quot;</span><span class="p">,</span> <span class="n">entities</span><span class="o">=</span><span class="p">[</span><span class="n">fstore</span><span class="o">.</span><span class="n">Entity</span><span class="p">(</span><span class="s2">&quot;ticker&quot;</span><span class="p">)],</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;spark&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>To use a remote execution engine, pass a <code class="docutils literal notranslate"><span class="pre">RunConfig</span></code> object as the <code class="docutils literal notranslate"><span class="pre">run_config</span></code> parameter for
the <code class="docutils literal notranslate"><span class="pre">ingest</span></code> API. The actual remote function to execute depends on the object passed:</p>
<ul class="simple">
<li><p>A default <code class="docutils literal notranslate"><span class="pre">RunConfig</span></code>, in which case the ingestion code either generates a new MLRun function runtime
of type <code class="docutils literal notranslate"><span class="pre">remote-spark</span></code>, or utilizes the function specified in <code class="docutils literal notranslate"><span class="pre">feature_set.spec.function</span></code> (in which case,
it has to be of runtime type <code class="docutils literal notranslate"><span class="pre">remote-spark</span></code> or <code class="docutils literal notranslate"><span class="pre">spark</span></code>).</p></li>
<li><p>A <code class="docutils literal notranslate"><span class="pre">RunConfig</span></code> that has a function configured within it. As mentioned, the function runtime must be of
type <code class="docutils literal notranslate"><span class="pre">remote-spark</span></code> or <code class="docutils literal notranslate"><span class="pre">spark</span></code>.</p></li>
</ul>
<p>Spark execution can be done locally, utilizing a local Spark session provided to the ingestion call. To use a local Spark session, pass a
Spark session context when calling the <a class="reference internal" href="../api/mlrun.feature_store.html#mlrun.feature_store.ingest" title="mlrun.feature_store.ingest"><code class="xref py py-func docutils literal notranslate"><span class="pre">ingest()</span></code></a> function, as the
<code class="docutils literal notranslate"><span class="pre">spark_context</span></code> parameter. This session is used for data operations and transformations.</p>
<p>See code examples in:</p>
<ul class="simple">
<li><p><a class="reference external" href="#local-spark-ingestion-example">Local Spark ingestion example</a></p></li>
<li><p><a class="reference external" href="#remote-spark-ingestion-example">Remote Spark ingestion example</a></p></li>
<li><p><a class="reference external" href="#spark-operator-ingestion-example">Spark operator ingestion example</a></p></li>
<li><p><a class="reference external" href="#spark-dataframe-ingestion-example">Spark dataframe ingestion example</a></p></li>
<li><p><a class="reference external" href="#spark-over-s3-full-flow-example">Spark over S3 full flow example</a></p></li>
<li><p><a class="reference external" href="#spark-ingestion-from-snowflake-example">Spark ingestion from Snowflake example</a></p></li>
<li><p><a class="reference external" href="#spark-ingestion-from-azure-example">Spark ingestion from Azure example</a></p></li>
</ul>
<section id="local-spark-ingestion-example">
<h2>Local Spark ingestion example<a class="headerlink" href="#local-spark-ingestion-example" title="Permalink to this headline">#</a></h2>
<p>A local Spark session is a session running in the Jupyter service.<br>
The following code executes data ingestion using a local Spark session.</p>
<p>When using a local Spark session, the <code class="docutils literal notranslate"><span class="pre">ingest</span></code> API would wait for its completion.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlrun</span>
<span class="kn">from</span> <span class="nn">mlrun.datastore.sources</span> <span class="kn">import</span> <span class="n">CSVSource</span>
<span class="kn">import</span> <span class="nn">mlrun.feature_store</span> <span class="k">as</span> <span class="nn">fstore</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">mlrun</span><span class="o">.</span><span class="n">get_or_create_project</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;stocks&quot;</span><span class="p">)</span>
<span class="n">feature_set</span> <span class="o">=</span> <span class="n">fstore</span><span class="o">.</span><span class="n">FeatureSet</span><span class="p">(</span><span class="s2">&quot;stocks&quot;</span><span class="p">,</span> <span class="n">entities</span><span class="o">=</span><span class="p">[</span><span class="n">fstore</span><span class="o">.</span><span class="n">Entity</span><span class="p">(</span><span class="s2">&quot;ticker&quot;</span><span class="p">)],</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;spark&quot;</span><span class="p">)</span>

<span class="c1"># add_aggregation can be used in conjunction with Spark</span>
<span class="n">feature_set</span><span class="o">.</span><span class="n">add_aggregation</span><span class="p">(</span><span class="s2">&quot;price&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;1h&quot;</span><span class="p">],</span> <span class="s2">&quot;10m&quot;</span><span class="p">)</span>

<span class="n">source</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="s2">&quot;mycsv&quot;</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;v3io:///projects/stocks.csv&quot;</span><span class="p">)</span>

<span class="c1"># Execution using a local Spark session</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;Spark function&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">fstore</span><span class="o">.</span><span class="n">ingest</span><span class="p">(</span><span class="n">feature_set</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">spark_context</span><span class="o">=</span><span class="n">spark</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="remote-spark-ingestion-example">
<h2>Remote Spark ingestion example<a class="headerlink" href="#remote-spark-ingestion-example" title="Permalink to this headline">#</a></h2>
<p>Remote Spark refers to  a session running from another service, for example, the Spark standalone service or the Spark operator service.
When using remote execution the MLRun run execution details are returned, allowing tracking of its status and results.</p>
<p>The following code should be executed only once to build the remote spark image before running the first ingest.
It may take a few minutes to prepare the image.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlrun.runtimes</span> <span class="kn">import</span> <span class="n">RemoteSparkRuntime</span>
<span class="n">RemoteSparkRuntime</span><span class="o">.</span><span class="n">deploy_default_image</span><span class="p">()</span>
</pre></div>
</div>
<p>Remote ingestion:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mlrun: start-code</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlrun.feature_store.api</span> <span class="kn">import</span> <span class="n">ingest</span>
<span class="k">def</span> <span class="nf">ingest_handler</span><span class="p">(</span><span class="n">context</span><span class="p">):</span>
    <span class="n">ingest</span><span class="p">(</span><span class="n">mlrun_context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span> <span class="c1"># The handler function must call ingest with the mlrun_context</span>
</pre></div>
</div>
<p>You can run your PySpark code for ingesting data into the feature store by adding:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_spark_func</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="s2">&quot;bid&gt;55&quot;</span><span class="p">)</span> <span class="c1"># PySpark code</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mlrun: end-code</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlrun.datastore.sources</span> <span class="kn">import</span> <span class="n">CSVSource</span>
<span class="kn">from</span> <span class="nn">mlrun</span> <span class="kn">import</span> <span class="n">code_to_function</span>
<span class="kn">import</span> <span class="nn">mlrun.feature_store</span> <span class="k">as</span> <span class="nn">fstore</span>

<span class="n">feature_set</span> <span class="o">=</span> <span class="n">fstore</span><span class="o">.</span><span class="n">FeatureSet</span><span class="p">(</span><span class="s2">&quot;stock-quotes&quot;</span><span class="p">,</span> <span class="n">entities</span><span class="o">=</span><span class="p">[</span><span class="n">fstore</span><span class="o">.</span><span class="n">Entity</span><span class="p">(</span><span class="s2">&quot;ticker&quot;</span><span class="p">)],</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;spark&quot;</span><span class="p">)</span>

<span class="n">source</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="s2">&quot;mycsv&quot;</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;v3io:///projects/quotes.csv&quot;</span><span class="p">)</span>

<span class="n">spark_service_name</span> <span class="o">=</span> <span class="s2">&quot;iguazio-spark-service&quot;</span> <span class="c1"># As configured &amp; shown in the Iguazio dashboard</span>

<span class="n">feature_set</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;s1&quot;</span><span class="p">,</span> <span class="n">handler</span><span class="o">=</span><span class="s2">&quot;my_spark_func&quot;</span><span class="p">)</span>
<span class="n">my_func</span> <span class="o">=</span> <span class="n">code_to_function</span><span class="p">(</span><span class="s2">&quot;func&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;remote-spark&quot;</span><span class="p">)</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">fstore</span><span class="o">.</span><span class="n">RunConfig</span><span class="p">(</span><span class="n">local</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">my_func</span><span class="p">,</span> <span class="n">handler</span><span class="o">=</span><span class="s2">&quot;ingest_handler&quot;</span><span class="p">)</span>
<span class="n">fstore</span><span class="o">.</span><span class="n">ingest</span><span class="p">(</span><span class="n">feature_set</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">run_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">spark_context</span><span class="o">=</span><span class="n">spark_service_name</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="spark-operator-ingestion-example">
<h2>Spark operator ingestion example<a class="headerlink" href="#spark-operator-ingestion-example" title="Permalink to this headline">#</a></h2>
<p>When running with a Spark operator, the MLRun execution details are returned, allowing tracking of the jobs status and results. Spark operator ingestion is always executed remotely.</p>
<p>The following code should be executed only once to build the spark job image before running the first ingest.
It may take a few minutes to prepare the image.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlrun.runtimes</span> <span class="kn">import</span> <span class="n">Spark3Runtime</span>
<span class="n">Spark3Runtime</span><span class="o">.</span><span class="n">deploy_default_image</span><span class="p">()</span>
</pre></div>
</div>
<p>Spark operator ingestion:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mlrun: start-code</span>

<span class="kn">from</span> <span class="nn">mlrun.feature_store.api</span> <span class="kn">import</span> <span class="n">ingest</span>

<span class="k">def</span> <span class="nf">ingest_handler</span><span class="p">(</span><span class="n">context</span><span class="p">):</span>
    <span class="n">ingest</span><span class="p">(</span><span class="n">mlrun_context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span> <span class="c1"># The handler function must call ingest with the mlrun_context</span>

<span class="c1"># You can add your own PySpark code as a graph step:</span>
<span class="k">def</span> <span class="nf">my_spark_func</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="s2">&quot;bid&gt;55&quot;</span><span class="p">)</span> <span class="c1"># PySpark code</span>

<span class="c1"># mlrun: end-code</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlrun.datastore.sources</span> <span class="kn">import</span> <span class="n">CSVSource</span>
<span class="kn">from</span> <span class="nn">mlrun</span> <span class="kn">import</span> <span class="n">code_to_function</span>
<span class="kn">import</span> <span class="nn">mlrun.feature_store</span> <span class="k">as</span> <span class="nn">fstore</span>

<span class="n">feature_set</span> <span class="o">=</span> <span class="n">fstore</span><span class="o">.</span><span class="n">FeatureSet</span><span class="p">(</span><span class="s2">&quot;stock-quotes&quot;</span><span class="p">,</span> <span class="n">entities</span><span class="o">=</span><span class="p">[</span><span class="n">fstore</span><span class="o">.</span><span class="n">Entity</span><span class="p">(</span><span class="s2">&quot;ticker&quot;</span><span class="p">)],</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;spark&quot;</span><span class="p">)</span>

<span class="n">source</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="s2">&quot;mycsv&quot;</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;v3io:///projects/quotes.csv&quot;</span><span class="p">)</span>

<span class="n">feature_set</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;s1&quot;</span><span class="p">,</span> <span class="n">handler</span><span class="o">=</span><span class="s2">&quot;my_spark_func&quot;</span><span class="p">)</span>

<span class="n">my_func</span> <span class="o">=</span> <span class="n">code_to_function</span><span class="p">(</span><span class="s2">&quot;func&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;spark&quot;</span><span class="p">)</span>

<span class="n">my_func</span><span class="o">.</span><span class="n">with_driver_requests</span><span class="p">(</span><span class="n">cpu</span><span class="o">=</span><span class="s2">&quot;200m&quot;</span><span class="p">,</span> <span class="n">mem</span><span class="o">=</span><span class="s2">&quot;1G&quot;</span><span class="p">)</span>
<span class="n">my_func</span><span class="o">.</span><span class="n">with_executor_requests</span><span class="p">(</span><span class="n">cpu</span><span class="o">=</span><span class="s2">&quot;200m&quot;</span><span class="p">,</span> <span class="n">mem</span><span class="o">=</span><span class="s2">&quot;1G&quot;</span><span class="p">)</span>
<span class="n">my_func</span><span class="o">.</span><span class="n">with_igz_spark</span><span class="p">()</span>

<span class="c1"># Enables using the default image (can be replace with specifying a specific image with .spec.image)</span>
<span class="n">my_func</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">use_default_image</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># Not a must - default: 1</span>
<span class="n">my_func</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">replicas</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># If needed, sparkConf can be modified like this:</span>
<span class="c1"># my_func.spec.spark_conf[&#39;spark.specific.config.key&#39;] = &#39;value&#39;</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">fstore</span><span class="o">.</span><span class="n">RunConfig</span><span class="p">(</span><span class="n">local</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">my_func</span><span class="p">,</span> <span class="n">handler</span><span class="o">=</span><span class="s2">&quot;ingest_handler&quot;</span><span class="p">)</span>
<span class="n">fstore</span><span class="o">.</span><span class="n">ingest</span><span class="p">(</span><span class="n">feature_set</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">run_config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="spark-dataframe-ingestion-example">
<h2>Spark dataframe ingestion example<a class="headerlink" href="#spark-dataframe-ingestion-example" title="Permalink to this headline">#</a></h2>
<p>The following code executes local data ingestion from a spark dataframe (Spark dataframe Ingestion cannot be executed remotely.)
The specified dataframe should be associated with <code class="docutils literal notranslate"><span class="pre">spark_context</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">import</span> <span class="nn">mlrun.feature_store</span> <span class="k">as</span> <span class="nn">fstore</span>

<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;count&quot;</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;12&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;14&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;88&quot;</span><span class="p">)]</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s1">&#39;example&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="o">*</span><span class="n">columns</span><span class="p">)</span>

<span class="n">fset</span> <span class="o">=</span> <span class="n">fstore</span><span class="o">.</span><span class="n">FeatureSet</span><span class="p">(</span><span class="s2">&quot;myset&quot;</span><span class="p">,</span> <span class="n">entities</span><span class="o">=</span><span class="p">[</span><span class="n">fstore</span><span class="o">.</span><span class="n">Entity</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">)],</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;spark&quot;</span><span class="p">)</span>

<span class="n">fstore</span><span class="o">.</span><span class="n">ingest</span><span class="p">(</span><span class="n">fset</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">spark_context</span><span class="o">=</span><span class="n">spark</span><span class="p">)</span>

<span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="spark-over-s3-full-flow-example">
<h2>Spark over S3 - full flow example<a class="headerlink" href="#spark-over-s3-full-flow-example" title="Permalink to this headline">#</a></h2>
<p>For Spark to work with S3, it requires several properties to be set. Spark over S3 can be executed both remotely and locally, as long as access credentials to the S3
objects are available to it. The following example writes a
feature set to S3 in the parquet format in a remote k8s job:</p>
<p>One-time setup:</p>
<ol class="arabic">
<li><p>Deploy the default image for your job (this takes several minutes but should be executed only once per cluster for any MLRun/Iguazio upgrade):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlrun.runtimes</span> <span class="kn">import</span> <span class="n">RemoteSparkRuntime</span>
<span class="n">RemoteSparkRuntime</span><span class="o">.</span><span class="n">deploy_default_image</span><span class="p">()</span>
</pre></div>
</div>
</li>
<li><p>Store your S3 credentials in a k8s <a class="reference external" href="../secrets.html#kubernetes-project-secrets">secret</a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlrun</span>
<span class="n">secrets</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;s3_access_key&#39;</span><span class="p">:</span> <span class="n">AWS_ACCESS_KEY</span><span class="p">,</span> <span class="s1">&#39;s3_secret_key&#39;</span><span class="p">:</span> <span class="n">AWS_SECRET_KEY</span><span class="p">}</span>
<span class="n">mlrun</span><span class="o">.</span><span class="n">get_run_db</span><span class="p">()</span><span class="o">.</span><span class="n">create_project_secrets</span><span class="p">(</span>
    <span class="n">project</span> <span class="o">=</span> <span class="s2">&quot;uhuh-proj&quot;</span><span class="p">,</span>
    <span class="n">provider</span><span class="o">=</span><span class="n">mlrun</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">schemas</span><span class="o">.</span><span class="n">SecretProviderName</span><span class="o">.</span><span class="n">kubernetes</span><span class="p">,</span>
    <span class="n">secrets</span><span class="o">=</span><span class="n">secrets</span>
<span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
<p>Ingestion job code (to be executed in the remote pod):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mlrun: start-code</span>

<span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkConf</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>


<span class="kn">from</span> <span class="nn">mlrun.feature_store.api</span> <span class="kn">import</span> <span class="n">ingest</span>
<span class="k">def</span> <span class="nf">ingest_handler</span><span class="p">(</span><span class="n">context</span><span class="p">):</span>
    <span class="n">conf</span> <span class="o">=</span> <span class="p">(</span><span class="n">SparkConf</span><span class="p">()</span>
            <span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.hadoop.fs.s3a.path.style.access&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.hadoop.fs.s3a.access.key&quot;</span><span class="p">,</span> <span class="n">context</span><span class="o">.</span><span class="n">get_secret</span><span class="p">(</span><span class="s1">&#39;s3_access_key&#39;</span><span class="p">))</span>
            <span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.hadoop.fs.s3a.secret.key&quot;</span><span class="p">,</span> <span class="n">context</span><span class="o">.</span><span class="n">get_secret</span><span class="p">(</span><span class="s1">&#39;s3_secret_key&#39;</span><span class="p">))</span>
            <span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.hadoop.fs.s3a.endpoint&quot;</span><span class="p">,</span> <span class="n">context</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="s2">&quot;s3_endpoint&quot;</span><span class="p">))</span>
            <span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.hadoop.fs.s3a.region&quot;</span><span class="p">,</span> <span class="n">context</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="s2">&quot;s3_region&quot;</span><span class="p">))</span>
            <span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.hadoop.fs.s3a.impl&quot;</span><span class="p">,</span> <span class="s2">&quot;org.apache.hadoop.fs.s3a.S3AFileSystem&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;com.amazonaws.services.s3.enableV4&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.driver.extraJavaOptions&quot;</span><span class="p">,</span> <span class="s2">&quot;-Dcom.amazonaws.services.s3.enableV4=true&quot;</span><span class="p">))</span>
    <span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="n">conf</span><span class="o">=</span><span class="n">conf</span><span class="p">)</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;S3 app&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
    <span class="p">)</span>
    
    <span class="n">ingest</span><span class="p">(</span><span class="n">mlrun_context</span><span class="o">=</span><span class="n">context</span><span class="p">,</span> <span class="n">spark_context</span><span class="o">=</span><span class="n">spark</span><span class="p">)</span>
    
<span class="c1"># mlrun: end-code</span>
</pre></div>
</div>
<p>Ingestion invocation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlrun.datastore.sources</span> <span class="kn">import</span> <span class="n">CSVSource</span>
<span class="kn">from</span> <span class="nn">mlrun.datastore.targets</span> <span class="kn">import</span> <span class="n">ParquetTarget</span>
<span class="kn">from</span> <span class="nn">mlrun</span> <span class="kn">import</span> <span class="n">code_to_function</span>
<span class="kn">import</span> <span class="nn">mlrun.feature_store</span> <span class="k">as</span> <span class="nn">fstore</span>

<span class="n">feature_set</span> <span class="o">=</span> <span class="n">fstore</span><span class="o">.</span><span class="n">FeatureSet</span><span class="p">(</span><span class="s2">&quot;stock-quotes&quot;</span><span class="p">,</span> <span class="n">entities</span><span class="o">=</span><span class="p">[</span><span class="n">fstore</span><span class="o">.</span><span class="n">Entity</span><span class="p">(</span><span class="s2">&quot;ticker&quot;</span><span class="p">)],</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;spark&quot;</span><span class="p">)</span>

<span class="n">source</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="s2">&quot;mycsv&quot;</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;v3io:///projects/quotes.csv&quot;</span><span class="p">)</span>

<span class="n">spark_service_name</span> <span class="o">=</span> <span class="s2">&quot;spark&quot;</span> <span class="c1"># As configured &amp; shown in the Iguazio dashboard</span>

<span class="n">fn</span> <span class="o">=</span> <span class="n">code_to_function</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;remote-spark&#39;</span><span class="p">,</span>  <span class="n">name</span><span class="o">=</span><span class="s1">&#39;func&#39;</span><span class="p">)</span>

<span class="n">run_config</span> <span class="o">=</span> <span class="n">fstore</span><span class="o">.</span><span class="n">RunConfig</span><span class="p">(</span><span class="n">local</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span> <span class="n">handler</span><span class="o">=</span><span class="s2">&quot;ingest_handler&quot;</span><span class="p">)</span>
<span class="n">run_config</span><span class="o">.</span><span class="n">with_secret</span><span class="p">(</span><span class="s1">&#39;kubernetes&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;s3_access_key&#39;</span><span class="p">,</span> <span class="s1">&#39;s3_secret_key&#39;</span><span class="p">])</span>
<span class="n">run_config</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;s3_endpoint&quot;</span> <span class="p">:</span> <span class="s2">&quot;s3.us-east-2.amazonaws.com&quot;</span><span class="p">,</span>
    <span class="s2">&quot;s3_region&quot;</span> <span class="p">:</span> <span class="s2">&quot;us-east-2&quot;</span>
<span class="p">}</span>

<span class="n">target</span> <span class="o">=</span> <span class="n">ParquetTarget</span><span class="p">(</span>
    <span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;s3://my-s3-bucket/some/path&quot;</span><span class="p">,</span>
    <span class="n">partitioned</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">fstore</span><span class="o">.</span><span class="n">ingest</span><span class="p">(</span><span class="n">feature_set</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="p">[</span><span class="n">target</span><span class="p">],</span> <span class="n">run_config</span><span class="o">=</span><span class="n">run_config</span><span class="p">,</span> <span class="n">spark_context</span><span class="o">=</span><span class="n">spark_service_name</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="spark-ingestion-from-snowflake-example">
<h2>Spark ingestion from Snowflake example<a class="headerlink" href="#spark-ingestion-from-snowflake-example" title="Permalink to this headline">#</a></h2>
<p>Spark ingestion from Snowflake can be executed both remotely and locally.</p>
<p>When running aggregations, they actually run on Spark and require Spark compute resources.<br>
The queries from the database are regular snowflake queries and they use Snowflake compute resources.</p>
<div class="admonition-note admonition">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">Entity</span></code> is case sensitive.</p>
</div>
<p>The following code executes local data ingestion from Snowflake.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="kn">import</span> <span class="nn">mlrun</span>
<span class="kn">import</span> <span class="nn">mlrun.feature_store</span> <span class="k">as</span> <span class="nn">fstore</span>
<span class="kn">from</span> <span class="nn">mlrun.datastore.sources</span> <span class="kn">import</span> <span class="n">SnowflakeSource</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;snowy&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="n">mlrun</span><span class="o">.</span><span class="n">get_or_create_project</span><span class="p">(</span><span class="s2">&quot;feature_store&quot;</span><span class="p">)</span>
<span class="n">feature_set</span> <span class="o">=</span> <span class="n">fstore</span><span class="o">.</span><span class="n">FeatureSet</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;customer&quot;</span><span class="p">,</span> <span class="n">entities</span><span class="o">=</span><span class="p">[</span><span class="n">fstore</span><span class="o">.</span><span class="n">Entity</span><span class="p">(</span><span class="s2">&quot;C_CUSTKEY&quot;</span><span class="p">)],</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;spark&quot;</span>
<span class="p">)</span>

<span class="n">source</span> <span class="o">=</span> <span class="n">SnowflakeSource</span><span class="p">(</span>
    <span class="s2">&quot;customer_sf&quot;</span><span class="p">,</span>
    <span class="n">query</span><span class="o">=</span><span class="s2">&quot;select * from customer limit 100000&quot;</span><span class="p">,</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;&lt;url&gt;&quot;</span><span class="p">,</span>
    <span class="n">user</span><span class="o">=</span><span class="s2">&quot;&lt;user&gt;&quot;</span><span class="p">,</span>
    <span class="n">password</span><span class="o">=</span><span class="s2">&quot;&lt;password&gt;&quot;</span><span class="p">,</span>
    <span class="n">database</span><span class="o">=</span><span class="s2">&quot;SNOWFLAKE_SAMPLE_DATA&quot;</span><span class="p">,</span>
    <span class="n">schema</span><span class="o">=</span><span class="s2">&quot;TPCH_SF1&quot;</span><span class="p">,</span>
    <span class="n">warehouse</span><span class="o">=</span><span class="s2">&quot;compute_wh&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">fstore</span><span class="o">.</span><span class="n">ingest</span><span class="p">(</span><span class="n">feature_set</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">spark_context</span><span class="o">=</span><span class="n">spark</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="spark-ingestion-from-azure-example">
<h2>Spark ingestion from Azure example<a class="headerlink" href="#spark-ingestion-from-azure-example" title="Permalink to this headline">#</a></h2>
<p>Spark ingestion from Azure can be executed both remotely and locally. The following code executes remote data ingestion from Azure.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlrun</span>

<span class="c1"># Initialize the MLRun project object</span>
<span class="n">project_name</span> <span class="o">=</span> <span class="s2">&quot;spark-azure-test&quot;</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">mlrun</span><span class="o">.</span><span class="n">get_or_create_project</span><span class="p">(</span><span class="n">project_name</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="s2">&quot;./&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">mlrun.runtimes</span> <span class="kn">import</span> <span class="n">RemoteSparkRuntime</span>
<span class="n">RemoteSparkRuntime</span><span class="o">.</span><span class="n">deploy_default_image</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">mlrun.datastore.sources</span> <span class="kn">import</span> <span class="n">CSVSource</span>
<span class="kn">from</span> <span class="nn">mlrun.datastore.targets</span> <span class="kn">import</span> <span class="n">ParquetTarget</span>
<span class="kn">from</span> <span class="nn">mlrun</span> <span class="kn">import</span> <span class="n">code_to_function</span>
<span class="kn">import</span> <span class="nn">mlrun.feature_store</span> <span class="k">as</span> <span class="nn">fstore</span>

<span class="n">feature_set</span> <span class="o">=</span> <span class="n">fstore</span><span class="o">.</span><span class="n">FeatureSet</span><span class="p">(</span><span class="s2">&quot;rides7&quot;</span><span class="p">,</span> <span class="n">entities</span><span class="o">=</span><span class="p">[</span><span class="n">fstore</span><span class="o">.</span><span class="n">Entity</span><span class="p">(</span><span class="s2">&quot;ride_id&quot;</span><span class="p">)],</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;spark&quot;</span><span class="p">,</span> <span class="n">timestamp_key</span><span class="o">=</span><span class="s2">&quot;key&quot;</span><span class="p">)</span>

<span class="n">source</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="s2">&quot;rides&quot;</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;wasbs://warroom@mlrunwarroom.blob.core.windows.net/ny_taxi_train_subset_ride_id.csv&quot;</span><span class="p">)</span>

<span class="n">spark_service_name</span> <span class="o">=</span> <span class="s2">&quot;spark-fs&quot;</span> <span class="c1"># As configured &amp; shown in the Iguazio dashboard</span>

<span class="n">fn</span> <span class="o">=</span> <span class="n">code_to_function</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;remote-spark&#39;</span><span class="p">,</span>  <span class="n">name</span><span class="o">=</span><span class="s1">&#39;func&#39;</span><span class="p">)</span>

<span class="n">run_config</span> <span class="o">=</span> <span class="n">fstore</span><span class="o">.</span><span class="n">RunConfig</span><span class="p">(</span><span class="n">local</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span> <span class="n">handler</span><span class="o">=</span><span class="s2">&quot;ingest_handler&quot;</span><span class="p">)</span>

<span class="n">target</span> <span class="o">=</span> <span class="n">ParquetTarget</span><span class="p">(</span><span class="n">partitioned</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">time_partitioning_granularity</span><span class="o">=</span><span class="s2">&quot;month&quot;</span><span class="p">)</span>

<span class="n">feature_set</span><span class="o">.</span><span class="n">set_targets</span><span class="p">(</span><span class="n">targets</span><span class="o">=</span><span class="p">[</span><span class="n">target</span><span class="p">],</span><span class="n">with_defaults</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">fstore</span><span class="o">.</span><span class="n">ingest</span><span class="p">(</span><span class="n">feature_set</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">run_config</span><span class="o">=</span><span class="n">run_config</span><span class="p">,</span> <span class="n">spark_context</span><span class="o">=</span><span class="n">spark_service_name</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../data-prep/ingest-data-fs.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Ingest data using the feature store</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../development/index.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Develop and train models</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Iguazio<br/>
  
      &copy; Copyright 2022, Iguazio.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>



<div class="footer"><!-- This page uses <a href="https://analytics.google.com/">
Google Analytics</a> to collect statistics. You can disable it by blocking
the JavaScript coming from www.google-analytics.com. -->

</div>

  </body>
</html>